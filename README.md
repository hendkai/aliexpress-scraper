# AliExpress Product Scraper

Ein leistungsstarkes und benutzerfreundliches Web-Interface zum Scrapen von Produktdaten von AliExpress Ã¼ber deren inoffizielle API.

![MIT License](https://img.shields.io/badge/License-MIT-green.svg)
![Python](https://img.shields.io/badge/Python-3.6+-blue.svg)

## Screenshots

### Such-Interface
![Search Interface](screenshots/Capture1.PNG)

### Ergebnisse und Feldauswahl
![Field Selection and Results](screenshots/Capture.PNG)

## Features

- ğŸŒ **Web-OberflÃ¤che**: Intuitive UI fÃ¼r einfache Bedienung
- ğŸš€ **API-basiertes Scraping**: Schnelle und effiziente Datenerfassung Ã¼ber die AliExpress-API
- ğŸ”’ **Intelligentes Session-Management**: Browser-Automatisierung nur fÃ¼r initiale Cookie-Erfassung
- ğŸ›¡ï¸ **Anti-Block-Schutz**: 
  - Konfigurierbare VerzÃ¶gerung zwischen Anfragen (0,2â€“10 Sekunden)
  - Serielle Verarbeitung zur Vermeidung von Blockaden
  - Session-Caching zur Minimierung von Browser-Automatisierung
- ğŸ“Š **Flexible Datenexporte**:
  - JSON-Format fÃ¼r vollstÃ¤ndige Datensicherung
  - CSV-Format fÃ¼r Tabellenkalkulationen
- ğŸ¯ **Feldauswahl**: Exakte Auswahl der zu extrahierenden Produktdetails
- ğŸ” **Erweiterte Filter**:
  - Preisbereich
  - Rabatt-Deals
  - Kostenloser Versand
- ğŸ“ **Echtzeit-Logging**: Live-Log der Scraping-Prozesse
- â° **Automatisches Scraping**: Zeitgesteuerte Aktualisierung und Keyword-basierte Ãœberwachung

## Projektstruktur

- `app.py` â€“ Flask Web-App mit Datenbankintegration
- `scraper.py` â€“ Zentrale Scraping-Logik und AliExpress-API
- `models.py` â€“ SQLAlchemy Datenbankmodelle
- `scheduler.py` â€“ Automatisches, zeitgesteuertes Scraping
- `templates/` â€“ Jinja2-Templates fÃ¼r die WeboberflÃ¤che
- `results/` â€“ Exportierte CSV- und JSON-Dateien
- `instance/aliexpress_scraper.db` â€“ SQLite-Datenbankdatei
- `session_cache.json` â€“ Zwischengespeicherte Sessiondaten

## Installation

1. Repository klonen:
```bash
git clone https://github.com/hendkai/aliexpress-scraper.git
cd aliexpress-scraper
```

2. AbhÃ¤ngigkeiten installieren:
```bash
pip install -r requirements.txt
```

## Nutzung

1. Web-OberflÃ¤che starten:
```bash
python app.py
```

2. Im Browser Ã¶ffnen:
```
http://localhost:5000
```

3. In der WeboberflÃ¤che:
   - Suchbegriff eingeben
   - Anzahl der zu scrapenden Seiten wÃ¤hlen (1â€“60)
   - Felder auswÃ¤hlen
   - Optionale Filter setzen (Preis, Rabatt, Versand)
   - AnfrageverzÃ¶gerung einstellen (empfohlen: 1 Sekunde)
   - Scraping starten und Fortschritt beobachten

4. Ergebnisse werden im Ordner `results/` gespeichert als:
   - `aliexpress_[keyword]_extracted.json`
   - `aliexpress_[keyword]_extracted.csv`

## Automatisches Scraping

Das System unterstÃ¼tzt zeitgesteuertes, automatisches Scraping Ã¼ber den eingebauten Scheduler (`scheduler.py`).
- Keywords kÃ¶nnen mit Intervall gepflegt werden (z.B. alle 6h).
- PreisverlÃ¤ufe und neue Produkte werden automatisch aktualisiert.
- Verwaltung und Statusanzeige Ã¼ber die WeboberflÃ¤che unter "Settings".

## Datenbankstruktur (Kernmodelle)

- **Product**: Produktdaten, Varianten, Shop, Preis, Status, Tracking
- **PriceHistory**: Historische PreisverlÃ¤ufe
- **SearchKeyword**: Ãœberwachte Suchbegriffe und deren Intervalle
- **ScrapingLog**: Protokollierung aller Scraping-AktivitÃ¤ten

## VerfÃ¼gbare Felder

- Product ID
- Title
- Sale Price
- Original Price
- Discount (%)
- Currency
- Rating
- Orders Count
- Store Name
- Store ID
- Store URL
- Product URL
- Image URL

## Best Practices

1. **AnfrageverzÃ¶gerung**:
   - Standard: 1 Sekunde zwischen Anfragen
   - Niedrigere Werte (0,2â€“0,5s) erhÃ¶hen das Blockier-Risiko
2. **Seitenanzahl**:
   - Maximal: 60 Seiten pro Suche
   - Mit Filtern gezielter suchen
3. **Session-Management**:
   - Sessiondaten werden 30 Minuten zwischengespeichert
   - Bei Problemen Cookies lÃ¶schen und Browser neu starten

## Lizenz

Dieses Projekt steht unter der MIT-Lizenz â€“ siehe [LICENSE](LICENSE).

## Hinweis

Dieses Tool dient ausschlieÃŸlich zu Bildungszwecken. Nutzung auf eigene Verantwortung und unter Beachtung der AliExpress-Nutzungsbedingungen. 